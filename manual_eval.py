from transformers import LlamaTokenizer, LlamaForCausalLM
import torch

tokenizer = LlamaTokenizer.from_pretrained('/ssd005/projects/llm/Llama-2-7b-chat-hf/')
tokenizer.add_special_tokens({"pad_token": "<pad>"})
tokenizer.model_max_length = 1024
model = LlamaForCausalLM.from_pretrained('/ssd005/projects/llm/clinical_llm/llama-2-7b-ft-mdpi-mtb/').cuda()
model.config.pad_token_id = tokenizer.pad_token_id
model.generation_config.pad_token_id = tokenizer.pad_token_id
model.generation_config.temperature = 0.7
# model.generation_config.temperature = 0.8
model.generation_config.top_p = 0.1
model.generation_config.top_k = 40
# model.generation_config.top_p = 0.95

instruction = "The following is a question about medical knowledge. Solve it in a step-by-step fashion, starting by summarizing the available information from the abstract. Output a single option from yes, no, or maybe."
# instruction = "The following is a question about medical knowledge. Output a single option from yes/no/maybe."
q1 = "Abstract: The use of open access endoscopy is increasing. Its effect on the adequacy of patient informed consent, procedure acceptance and the impact on subsequent communication/transfer of procedure results to the patient have not been evaluated. The aim of our study was to compare the extent of preknowledge of procedures and test explanation, patient medical complexity, information transfer and overall patient satisfaction between a patient group referred for outpatient open access endoscopy versus a patient group from a gastrointestinal (GI) subspecialty clinic.\nInformation was obtained from all patients presenting for outpatient upper and lower endoscopy by using a 1-page questionnaire. Patients from the two groups who had an outpatient upper/lower endoscopic procedure were contacted by phone after the procedure to obtain information with a standardized questionnaire.\nThe open access patients reported receiving significantly less information to help them identify the procedure (p<0.01) and less explanation concerning the nature of the procedure than the group of patients referred from the subspecialty clinic (p<0.005). There was no difference between the two groups in satisfaction scores for examinations performed under conscious sedation. For flexible sigmoidoscopy without sedation, however, the GI clinic patient group were more satisfied with their procedure. The majority of patients, regardless of access, were more likely to receive endoscopic results from a gastroenterologist than the referring physician. Furthermore, the patients in the GI clinic group who underwent colonoscopy felt significantly better at follow-up.\nQuestion: Does open access endoscopy close the door to an adequately informed patient?\nAnswer:"
q2 = "Abstract: To examine the evidence base of sports medicine research and assess how relevant and applicable it is to everyday practice.\nOriginal research articles, short reports, and case reports published in four major sport and exercise medicine journals were studied and classified according to the main topic of study and type of subjects used.\nThe most common topic was sports science, and very few studies related to the treatment of injuries and medical conditions. The majority of published articles used healthy subjects sampled from the sedentary population, and few studies have been carried out on injured participants.\nQuestion: Are sports medicine journals relevant and applicable to practitioners and athletes?\nAnswer:"
q3 = "Abstract: To evaluate the effectiveness of feeding information on pharmacy back to primary care doctors in order to create awareness (knowledge) of pharmaceutical expenditure (PE).\nRetrospective cross-sectional study, through personal interview.\nReformed PC, Sabadell, Barcelona.\nThe 80 PC doctors working with primary care teams.\nAs the personal feed-back on PE, each doctor was asked for the PE generated during 1997 and the mean cost of prescriptions to active and pensioner patients. The statistical test used was the t test to compare means for paired data, with p<0.05 the required level of significance.\nOut of the total doctors interviewed (80), 71 replies were obtained for the annual PE and 76 for the mean cost of prescriptions, for both active and pensioner patients. Significant differences were found between the annual PE in reality and doctors' estimates: around twelve million pesetas. The differences between the real mean costs of prescription and the estimates were also significant.\nQuestion: Is there awareness of pharmaceutical expenditure in the reformed primary care system?\nAnswer:"
q4 = "Abstract: A multicentre, retrospective study was conducted of patients with rectal cancer threatening or affecting the prostatic plane, but not the bladder, judged by magnetic resonance imaging (MRI). The use of preoperative chemoradiotherapy and the type of urologic resection were correlated with the status of the pathological circumferential resection margin (CRM) and local recurrence.\nA consecutive series of 126 men with rectal cancer threatening (44) or affecting (82) the prostatic plane on preoperative staging and operated with local curative intent between 1998 and 2010 was analysed. In patients who did not have chemoradiotherapy but had a preoperative threatened anterior margin the CRM-positive rate was 25.0%. In patients who did not have preoperative chemoradiotherapy but did have an affected margin, the CRM-positive rate was 41.7%. When preoperative radiotherapy was given, the respective CRM infiltration rates were 7.1 and 20.7%. In patients having preoperative chemoradiotherapy followed by prostatic resection the rate of CRM positivity was 2.4%. Partial prostatectomy after preoperative chemoradiotherapy resulted in a free anterior CRM in all cases, but intra-operative urethral damage occurred in 36.4% of patients who underwent partial prostatectomy, resulting in a postoperative urinary fistula in 18.2% of patients.\nQuestion: Rectal cancer threatening or affecting the prostatic plane: is partial prostatectomy oncologically adequate?\nAnswer:"
q5 = "Abstract: To investigate the effectiveness of acupuncture in treating phonotraumatic vocal fold lesions.STUDY DESIGN/\nA total of 123 dysphonic individuals with benign vocal pathologies were recruited. They were given either genuine acupuncture (n = 40), sham acupuncture (n = 44), or no treatment (n = 39) for 6 weeks (two 30-minute sessions/wk). The genuine acupuncture group received needles puncturing nine voice-related acupoints for 30 minutes, two times a week for 6 weeks, whereas the sham acupuncture group received blunted needles stimulating the skin surface of the nine acupoints for the same frequency and duration. The no-treatment group did not receive any intervention but attended just the assessment sessions. One-hundred seventeen subjects completed the study (genuine acupuncture = 40; sham acupuncture = 43; and no treatment = 34), but only 84 of them had a complete set of vocal functions and quality of life measures (genuine acupuncture = 29; sham acupuncture = 33; and no-treatment = 22) and 42 of them with a complete set of endoscopic data (genuine acupuncture = 16; sham acupuncture = 15; and no treatment = 11).\nSignificant improvement in vocal function, as indicated by the maximum fundamental frequency produced, and also perceived quality of life, were found in both the genuine and sham acupuncture groups, but not in the no-treatment group. Structural (morphological) improvements were, however, only noticed in the genuine acupuncture group, which demonstrated a significant reduction in the size of the vocal fold lesions.\nQuestion: Is Acupuncture Efficacious for Treating Phonotraumatic Vocal Pathologies?\nAnswer:"
qs = [q1, q2, q3, q4, q5]
import pdb; pdb.set_trace()
for question in qs:
    prompt = 'Prompt: {}\n\n{}'.format(instruction, question)
    tokenized_user = tokenizer.encode(f"{prompt}", add_special_tokens=False)
    model_generation1 = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.8, do_sample=True, temperature=0.95)[:, len(tokenized_user):]
    model_generation2 = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.8, do_sample=True, temperature=0.95, repetition_penalty=1/0.85)[:, len(tokenized_user):]
    model_generation3 = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.1, do_sample=True, temperature=0.7, top_k=40, repetition_penalty=1/0.85)[:, len(tokenized_user):]
    model_generation4 = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.1, do_sample=True, temperature=0.7, top_k=40)[:, len(tokenized_user):]

    ans1=tokenizer.batch_decode(model_generation1, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    ans2=tokenizer.batch_decode(model_generation2, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    ans3=tokenizer.batch_decode(model_generation3, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    ans4=tokenizer.batch_decode(model_generation4, skip_special_tokens=True, clean_up_tokenization_spaces=True)
    
import pdb; pdb.set_trace()
prompt = 'Prompt: {}\n\n{}'.format(instruction, q1)
# BOS, EOS = tokenizer.bos_token, tokenizer.eos_token
# tokenized_user = tokenizer.encode(f"{BOS}{prompt}{EOS}", add_special_tokens=False)
tokenized_user = tokenizer.encode(f"{prompt}", add_special_tokens=False)
model_generation = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.8, do_sample=True, temperature=0.95)[:, len(tokenized_user):]
model_generation = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.8, do_sample=True, temperature=0.95, repetition_penalty=1/0.85)[:, len(tokenized_user):]
model_generation = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.1, do_sample=True, temperature=0.7, top_k=40, repetition_penalty=1/0.85)[:, len(tokenized_user):]
model_generation = model.generate(torch.tensor(tokenized_user).reshape(1, -1).cuda(), max_length=1024, top_p=0.1, do_sample=True, temperature=0.7, top_k=40)[:, len(tokenized_user):]

print(tokenizer.batch_decode(model_generation, skip_special_tokens=True, clean_up_tokenization_spaces=True))